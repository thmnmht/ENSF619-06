{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=0, model='Ensemble', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='custom', root_path='./dataset/btc/', data_path='BTC-Hourly.csv', features='S', target='close', freq='h', detail_freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, train_epochs=100, batch_size=1, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', task_id='custom')\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def main():\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, default=0, help='status')\n",
    "parser.add_argument('--model', type=str, default='Ensemble',\n",
    "                    help='model name, options: [FEDformer, Autoformer, Informer, Ensemble]')\n",
    "\n",
    "# supplementary config for FEDformer model\n",
    "parser.add_argument('--version', type=str, default='Fourier',\n",
    "                    help='for FEDformer, there are two versions to choose, options: [Fourier, Wavelets]')\n",
    "parser.add_argument('--mode_select', type=str, default='random',\n",
    "                    help='for FEDformer, there are two mode selection method, options: [random, low]')\n",
    "parser.add_argument('--modes', type=int, default=64, help='modes to be selected random 64')\n",
    "parser.add_argument('--L', type=int, default=3, help='ignore level')\n",
    "parser.add_argument('--base', type=str, default='legendre', help='mwt base')\n",
    "parser.add_argument('--cross_activation', type=str, default='tanh',\n",
    "                    help='mwt cross atention activation function tanh or softmax')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, default='custom', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./dataset/btc/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='BTC-Hourly.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='S',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, '\n",
    "                            'S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='close', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, '\n",
    "                            'b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--detail_freq', type=str, default='h', help='like freq, but use in predict')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\n",
    "# parser.add_argument('--cross_activation', type=str, default='tanh'\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--enc_in', type=int, default=1, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=1, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=1, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', default=[24], help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=3, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=100, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1', help='device ids of multi gpus')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.task_id = args.data\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.dvices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "# Exp = Exp_Main\n",
    "\n",
    "# if args.is_training:\n",
    "#     for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "# setting = '{}_{}_{}_modes{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "#     args.task_id,\n",
    "#     args.model,\n",
    "#     args.mode_select,\n",
    "#     args.modes,\n",
    "#     args.data,\n",
    "#     args.features,\n",
    "#     args.seq_len,\n",
    "#     args.label_len,\n",
    "#     args.pred_len,\n",
    "#     args.d_model,\n",
    "#     args.n_heads,\n",
    "#     args.e_layers,\n",
    "#     args.d_layers,\n",
    "#     args.d_ff,\n",
    "#     args.factor,\n",
    "#     args.embed,\n",
    "#     args.distil,\n",
    "#     args.des,\n",
    "#     0)\n",
    "\n",
    "            # exp = Exp(args)  # set experiments\n",
    "            # print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "            # exp.train(setting)\n",
    "\n",
    "            # print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            # exp.test(setting)\n",
    "\n",
    "            # if args.do_predict:\n",
    "            #     print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            #     exp.predict(setting, True)\n",
    "\n",
    "            # torch.cuda.empty_cache()\n",
    "    # else:\n",
    "    #     ii = 0\n",
    "    #     setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.task_id,\n",
    "    #                                                                                                   args.model,\n",
    "    #                                                                                                   args.data,\n",
    "    #                                                                                                   args.features,\n",
    "    #                                                                                                   args.seq_len,\n",
    "    #                                                                                                   args.label_len,\n",
    "    #                                                                                                   args.pred_len,\n",
    "    #                                                                                                   args.d_model,\n",
    "    #                                                                                                   args.n_heads,\n",
    "    #                                                                                                   args.e_layers,\n",
    "    #                                                                                                   args.d_layers,\n",
    "    #                                                                                                   args.d_ff,\n",
    "    #                                                                                                   args.factor,\n",
    "    #                                                                                                   args.embed,\n",
    "    #                                                                                                   args.distil,\n",
    "    #                                                                                                   args.des, ii)\n",
    "\n",
    "    #     exp = Exp(args)  # set experiments\n",
    "    #     print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    #     exp.test(setting, test=1)\n",
    "    #     torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation used !\n",
      "Autocorrelation used !\n",
      "Autocorrelation used !\n",
      "Autocorrelation used !\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 6556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/amirhossein/Projects/FEDformer/main.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m batch_x_mark \u001b[39m=\u001b[39m batch_x_mark\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m x_mark_np \u001b[39m=\u001b[39m data_set\u001b[39m.\u001b[39minverse_transform(batch_x_mark[\u001b[39m0\u001b[39m,:,:]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())[:,\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m batch_y_mark \u001b[39m=\u001b[39m batch_y_mark\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# decoder input\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m dec_inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(batch_y[:, \u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mpred_len:, :])\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;32m/home/amirhossein/Projects/FEDformer/main.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m batch_x_mark \u001b[39m=\u001b[39m batch_x_mark\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m x_mark_np \u001b[39m=\u001b[39m data_set\u001b[39m.\u001b[39minverse_transform(batch_x_mark[\u001b[39m0\u001b[39m,:,:]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())[:,\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m batch_y_mark \u001b[39m=\u001b[39m batch_y_mark\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# decoder input\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m dec_inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(batch_y[:, \u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mpred_len:, :])\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/fedformer/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fedformer/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.Ensemble import Model as Ensemble\n",
    "from data_provider.data_factory import data_provider\n",
    "\n",
    "\n",
    "path = '/home/amirhossein/Projects/FEDformer/checkpoints/custom_Ensemble_random_modes64_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_test_0'\n",
    "best_model_path = path + '/' + 'checkpoint.pth'\n",
    "model = Ensemble(args)\n",
    "\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "data_set, data_loader = data_provider(args, 'test')\n",
    "\n",
    "batch_num = 0\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(data_loader):\n",
    "    if i == batch_num:\n",
    "        batch_x = batch_x.float()\n",
    "        batch_y = batch_y.float()\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float()\n",
    "        batch_y_mark = batch_y_mark.float()\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "        pred = model(batch_x, batch_x_mark, dec_inp, batch_y_mark).detach()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3916.540771484375, 3892.909912109375, 3883.741943359375, 3883.999755859375, 3884.870849609375, 3894.310302734375, 3899.700927734375, 3894.730224609375, 3883.890380859375, 3888.460693359375, 3909.441162109375, 3890.909912109375, 3929.999755859375, 3949.611083984375, 3927.900146484375, 3936.999755859375, 3942.560302734375, 3951.739990234375, 3933.140380859375, 3954.060302734375, 3891.210693359375, 3875.290771484375, 3873.919677734375, 3861.550537109375, 3885.909912109375, 3889.950927734375, 3878.271240234375, 3869.941162109375, 3876.029052734375, 3867.628662109375, 3855.989990234375, 3864.198974609375, 3922.001708984375, 3869.800537109375, 3859.810302734375, 3851.980224609375, 3864.999755859375, 3864.849365234375, 3882.448974609375, 3868.310302734375, 3861.339599609375, 3803.579833984375, 3798.968505859375, 3798.759521484375, 3732.169677734375, 3708.300537109375, 3687.888427734375, 3705.269287109375, 3695.370849609375, 3689.659912109375, 3693.771240234375, 3680.989990234375, 3672.980224609375, 3684.329833984375, 3672.081787109375, 3643.368896484375, 3657.689208984375, 3625.601318359375, 3600.999755859375, 3585.409912109375, 3572.790771484375, 3571.120849609375, 3572.560302734375, 3575.579833984375, 3569.890380859375, 3566.808349609375, 3571.929443359375, 3567.999755859375, 3563.769287109375, 3582.489990234375, 3587.669677734375, 3599.089599609375, 3595.909912109375, 3597.749755859375, 3594.499755859375, 3598.450927734375, 3595.029052734375, 3587.970458984375, 3583.618896484375, 3586.380615234375, 3582.150146484375, 3579.919677734375, 3589.700927734375, 3595.999755859375, 3597.691162109375, 3594.820068359375, 3592.509521484375, 3592.070068359375, 3594.470458984375, 3597.099365234375, 3598.409912109375, 3597.409912109375, 3586.230224609375, 3588.169677734375, 3585.810302734375, 3584.050537109375]\n",
      "[3588.009521484375, 3583.210693359375, 3583.169677734375, 3580.628662109375, 3583.269287109375, 3588.970458984375, 3578.948974609375, 3574.441162109375, 3573.601318359375, 3566.290771484375, 3564.669677734375, 3564.208740234375, 3565.099365234375, 3562.618896484375, 3566.761474609375, 3564.409912109375, 3561.769287109375, 3556.458740234375, 3553.239990234375, 3586.851318359375, 3582.800537109375, 3574.880615234375, 3580.570068359375, 3570.511474609375, 3575.599365234375, 3576.519287109375, 3578.310302734375, 3576.019287109375, 3580.300537109375, 3573.298583984375, 3569.820068359375, 3570.271240234375, 3563.800537109375, 3560.460693359375, 3562.710693359375, 3569.919677734375, 3565.079833984375, 3572.698974609375, 3574.679443359375, 3569.700927734375, 3567.929443359375, 3567.659912109375, 3561.228271484375, 3562.839599609375, 3555.720458984375, 3554.169677734375, 3560.611083984375, 3570.400146484375, 3566.111083984375, 3566.720458984375, 3575.150146484375, 3573.630615234375, 3581.980224609375, 3570.720458984375, 3574.390380859375, 3579.700927734375, 3582.349365234375, 3574.931396484375, 3572.538818359375, 3571.989990234375, 3568.310302734375, 3572.550537109375, 3578.700927734375, 3577.359130859375, 3574.919677734375, 3561.130615234375, 3571.970458984375, 3578.298583984375, 3580.259521484375, 3574.880615234375, 3579.281005859375, 3580.759521484375, 3580.489990234375, 3589.589599609375, 3597.519287109375, 3601.489990234375, 3593.079833984375, 3600.999755859375, 3598.841552734375, 3594.798583984375, 3595.960693359375, 3585.939208984375, 3580.249755859375, 3577.519287109375, 3604.568115234375, 3598.698974609375, 3597.460693359375, 3581.111083984375, 3576.439208984375, 3571.800537109375, 3575.599365234375, 3577.800537109375, 3579.269287109375, 3568.999755859375, 3562.361083984375, 3566.001708984375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3584.050537109375, 6772.71435546875, 6665.30029296875, 6891.14794921875, 6722.99560546875, 7011.68896484375, 6396.66748046875, 6677.93896484375, 6156.89599609375, 5860.49169921875, 6062.16748046875, 5821.43310546875, 6322.13623046875, 5717.81396484375, 6027.61669921875, 6361.77294921875, 6196.98779296875, 6469.24755859375, 6386.08154296875, 5989.24951171875, 5825.63232421875, 6198.60888671875, 6648.90966796875, 6304.59716796875, 6629.96240234375, 6122.64208984375, 5759.85693359375, 6099.47021484375, 5834.17724609375, 5883.33154296875, 6351.19677734375, 5889.79443359375, 5646.81396484375, 6079.33740234375, 6225.65966796875, 6290.75146484375, 6261.69091796875, 6169.19482421875, 6263.75927734375, 5947.79052734375, 6044.85107421875, 6136.18505859375, 6218.54052734375, 5937.28466796875, 6009.23388671875, 5722.41357421875, 6326.72021484375, 6013.18310546875, 6016.86474609375, 5638.47216796875, 5802.23583984375, 6063.53076171875, 6015.75732421875, 6278.78466796875, 6127.93896484375, 6351.67529296875, 6419.36083984375, 6222.09912109375, 6466.49951171875, 6322.58935546875, 6469.85888671875, 6095.79248046875, 6210.33935546875, 6142.52490234375, 6711.20068359375, 6256.01318359375, 6239.09716796875, 6229.36279296875, 5915.57958984375, 6143.39794921875, 6465.54638671875, 6496.03271484375, 6134.36279296875, 6211.63427734375, 6176.35302734375, 6097.42529296875, 6139.72216796875, 6226.28662109375, 6570.91943359375, 5934.14990234375, 6311.51708984375, 5987.56201171875, 5798.81982421875, 5827.68310546875, 5758.17724609375, 6308.94873046875, 6067.89990234375, 5745.88037109375, 6042.25732421875, 6035.26318359375, 6186.16162109375, 5838.10693359375, 6231.85302734375, 5687.85498046875, 6246.49169921875, 6484.78857421875, 6484.99169921875]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = batch_x\n",
    "y = batch_y\n",
    "\n",
    "i = 0\n",
    "f = 0\n",
    "\n",
    "x_np = data_set.inverse_transform(x[i,:,:].detach().numpy())[:,f]\n",
    "y_np = data_set.inverse_transform(y[i,-args.pred_len:,:].detach().numpy())[:,f]\n",
    "pred_np = np.concatenate((x_np[-1:], data_set.inverse_transform(pred[i,:,:].detach().numpy())[:,f]))\n",
    "\n",
    "# true = np.concatenate([x_np, y_np])\n",
    "# x_true = np.arange(len(true))\n",
    "# x_pred = np.arange(len(true)-len(y_np)-1, len(true))\n",
    "print(x_np.tolist())\n",
    "print(y_np.tolist())\n",
    "print(pred_np.tolist())\n",
    "\n",
    "# plt.figure(figsize=(15, 6))\n",
    "\n",
    "# plt.plot(x_true, true, label=\"Real values\")\n",
    "# plt.plot(x_pred, pred_np, label=\"DLinear\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/amirhossein/Projects/FEDformer/main.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m}\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B100.82.128.57/home/amirhossein/Projects/FEDformer/main.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m a[\u001b[39m'\u001b[39;49m\u001b[39mc\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from models.Ensemble import Model as Ensemble\n",
    "# from models import FEDformer, Autoformer, Informer, Transformer, Ensemble\n",
    "import torch.nn as nn\n",
    "from data_provider.data_factory import data_provider\n",
    "\n",
    "# from my_dataset import MyDataset\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "path = '/home/amirhossein/Projects/FEDformer/checkpoints/custom_Ensemble_random_modes64_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_test_0'\n",
    "best_model_path = path + '/' + 'checkpoint.pth'\n",
    "model = Ensemble(args)\n",
    "\n",
    "# if args.use_multi_gpu and args.use_gpu:\n",
    "#     model = nn.DataParallel(model, device_ids=args.device_ids)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# DataLoader\n",
    "data_set, data_loader = data_provider(args, 'test')\n",
    "# dataset = MyDataset()  \n",
    "# dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "global_input_output_pairs = []\n",
    "\n",
    "@app.route('/get-io-pair', methods=['GET'])\n",
    "def get_io_pair():\n",
    "    # Return the most recent input-output pair\n",
    "    if global_input_output_pairs:\n",
    "        io_pair = global_input_output_pairs[-1]\n",
    "        return jsonify({'input': io_pair['input'].tolist(), 'output': io_pair['output'].tolist()})\n",
    "    else:\n",
    "        return jsonify({'error': 'No input-output pair available yet.'})\n",
    "\n",
    "def run_inference_loop():\n",
    "    # Iterates over the DataLoader\n",
    "    for inputs in test_loader:\n",
    "        # Sleep 1 second\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Generate output from the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Store the input-output pair\n",
    "        global_input_output_pairs.append({\n",
    "            'input': inputs,\n",
    "            'output': outputs\n",
    "        })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Start the Flask server in a separate thread\n",
    "    from threading import Thread\n",
    "    flask_thread = Thread(target=lambda: app.run(debug=True, use_reloader=False))\n",
    "    flask_thread.start()\n",
    "    \n",
    "    # Run the inference loop\n",
    "    run_inference_loop()\n",
    "\n",
    "    # Wait for the Flask server to end\n",
    "    flask_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
